# Human-AI Trust Studies

This repository contains comprehensive research on trust in human-AI collaboration, featuring two complementary studies examining different factors that influence trust formation and maintenance in virtual reality environments.

## Repository Structure

```
Human-AI-Trust-Studies/
├── Study1_Memory_Personality_Trust/    # Memory function and personality matching effects
├── Study2_Distance_Proximity_Trust/    # Spatial proximity effects on trust
└── Shared_Resources/                   # Common functions and documentation
```

## Studies Overview

### Study 1: Memory Function and Personality Matching Effects on Trust
**Research Question**: How do memory function and personality matching between humans and AI agents influence trust development in collaborative VR tasks?

**Key Findings**:
- Memory function significantly affects trust development patterns
- Personality matching influences agent perceptions and compliance behaviors
- Trust development varies by agent personality type (extrovert vs. introvert)
- Memory function affects decision time and learning curves

**Data**: 92 participants in VR maze navigation task
**Conditions**: 2 (Memory Function) × 2 (Agent Personality) = 4 conditions

### Study 2: Distance Proximity Effects on Trust
**Research Question**: How does spatial proximity between humans and AI agents influence trust dynamics and collaborative effectiveness?

**Key Findings**:
- Distance proximity significantly affects trust development (d = -0.578)
- Close agents (1.8m) facilitate positive trust building
- Distant agents (5.4m) lead to trust deterioration
- Proximity affects compliance behaviors and decision confidence
- Learning improvement enhanced with closer agents

**Data**: 92 participants in VR maze navigation task
**Conditions**: 2 distance conditions (1.8m vs. 5.4m)

## Key Contributions

1. **Theoretical**: Extends proxemics theory and trust models to human-AI interaction
2. **Methodological**: Comprehensive trust measurement across multiple dimensions
3. **Practical**: Design implications for VR and mixed reality applications
4. **Empirical**: Large-scale studies with significant effect sizes

## Repository Contents

Each study contains:
- **Analysis Scripts**: Python code for data processing and statistical analysis
- **Results**: Complete LaTeX manuscripts and supplementary figures
- **Data**: Processed datasets (anonymized)
- **Summaries**: Key findings and insights
- **Surveys**: Qualtrics survey files and questionnaires

## Getting Started

1. Navigate to the study of interest (`Study1_Memory_Personality_Trust/` or `Study2_Distance_Proximity_Trust/`)
2. Check the study-specific README for detailed information
3. Review the analysis scripts in the `analysis/` folder
4. Examine results in the `results/` folder
5. Upload Qualtrics surveys to the `surveys/` folder

## Requirements

- Python 3.8+
- Required packages listed in `requirements.txt`
- LaTeX (for manuscript compilation)

## Citation

If you use this research, please cite:

```bibtex
@article{human_ai_trust_studies_2024,
  title={Trust in Human-AI Collaboration: Effects of Memory Function, Personality Matching, and Spatial Proximity},
  author={[Author Names]},
  journal={[Journal Name]},
  year={2024}
}
```

## Contact

For questions about this research, please contact [Contact Information].

## License

This project is licensed under the MIT License - see the LICENSE file for details.

