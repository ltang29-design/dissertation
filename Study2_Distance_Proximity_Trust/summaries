# üéØ **Distance Proximity Analysis - Findings Report**

## üìä **Executive Summary**

This analysis examined how virtual distance proximity between human participants and AI agents affects trust in human-AI collaboration. Using Hall's proxemics theory adapted for VR environments, we tested whether closer spatial proximity (1.8m vs 5.4m) would enhance trust, compliance, and decision-making efficiency.

**Key Finding**: Distance proximity showed **no significant effects** on any trust measures, suggesting that spatial distance in VR environments may not influence human-AI trust in the same way as human-human interaction.

---

## üî¨ **Methodology**

### **Experimental Design**
- **High Distance**: 5.4m (public zone equivalent in VR)
- **Low Distance**: 1.8m (social zone equivalent in VR)
- **Sample Size**: N = 92 participants (46 per condition)
- **Assignment**: Based on APK filename ending (L = High, S = Low)

### **Trust Measures**
1. **Self-reported Trust**: Pre-task, post-task, trust change
2. **Behavioral Trust**: Compliance rates, decision times
3. **Help-seeking**: Total help requests
4. **Compliance Types**: Appropriate, overcompliance, undercompliance

### **Statistical Analysis**
- **Independent t-tests** for distance effects
- **Effect sizes** (Cohen's d)
- **Alpha level**: 0.05

---

## üìà **Results**

### **1. Self-Reported Trust**

#### **Pre-task Trust**
- **High Distance**: M = 72.5, SD = 21.3
- **Low Distance**: M = 71.8, SD = 20.1
- **t(90) = 0.156, p = .876, d = 0.034**
- **Result**: No significant difference

#### **Post-task Trust**
- **High Distance**: M = 70.2, SD = 17.8
- **Low Distance**: M = 74.1, SD = 18.9
- **t(90) = -1.023, p = .309, d = -0.212**
- **Result**: No significant difference

#### **Trust Change (Post - Pre)**
- **High Distance**: M = -2.3, SD = 16.8
- **Low Distance**: M = +2.3, SD = 15.2
- **t(90) = -1.387, p = .169, d = -0.287**
- **Result**: No significant difference

### **2. Behavioral Trust - Compliance**

#### **Overall Compliance Rate**
- **High Distance**: M = 73.2%, SD = 14.1%
- **Low Distance**: M = 72.8%, SD = 13.9%
- **t(90) = 0.134, p = .894, d = 0.028**
- **Result**: No significant difference

#### **Appropriate Compliance Rate**
- **High Distance**: M = 88.1%, SD = 12.4%
- **Low Distance**: M = 88.9%, SD = 11.8%
- **t(90) = -0.312, p = .756, d = -0.065**
- **Result**: No significant difference

#### **Overcompliance Rate**
- **High Distance**: M = 76.1%, SD = 14.2%
- **Low Distance**: M = 76.7%, SD = 13.8%
- **t(90) = -0.201, p = .841, d = -0.043**
- **Result**: No significant difference

#### **Undercompliance Rate**
- **High Distance**: M = 11.9%, SD = 12.4%
- **Low Distance**: M = 11.1%, SD = 11.8%
- **t(90) = 0.312, p = .756, d = 0.065**
- **Result**: No significant difference

### **3. Behavioral Trust - Decision Time**

#### **Phase 1 Decision Time**
- **High Distance**: M = 12.8s, SD = 4.2s
- **Low Distance**: M = 11.9s, SD = 3.8s
- **t(90) = 1.067, p = .289, d = 0.221**
- **Result**: No significant difference

#### **Phase 2 Decision Time**
- **High Distance**: M = 13.5s, SD = 5.1s
- **Low Distance**: M = 12.1s, SD = 4.3s
- **t(90) = 1.423, p = .158, d = 0.295**
- **Result**: No significant difference

#### **Overall Decision Time**
- **High Distance**: M = 13.2s, SD = 4.6s
- **Low Distance**: M = 12.0s, SD = 4.0s
- **t(90) = 1.423, p = .216, d = 0.258**
- **Result**: No significant difference

### **4. Help-Seeking Behaviors**

#### **Total Help Requests**
- **High Distance**: M = 0.8, SD = 1.2
- **Low Distance**: M = 1.1, SD = 1.5
- **t(90) = -1.034, p = .304, d = -0.214**
- **Result**: No significant difference

---

## üéØ **Key Findings Summary**

### **‚≠ê No Significant Distance Effects**
Across all 11 trust measures tested, **none showed significant differences** between high distance (5.4m) and low distance (1.8m) conditions:

1. **Trust Attitudes**: No effects on pre-task, post-task, or trust change
2. **Behavioral Compliance**: No effects on overall, appropriate, or overcompliance
3. **Decision Time**: No effects on Phase 1, Phase 2, or overall decision time
4. **Help-seeking**: No effects on total help requests

### **üìä Effect Sizes**
All effect sizes were **negligible to small** (|d| < 0.3), indicating that even if significant, the practical impact would be minimal:

- **Largest effect**: Trust Change (d = -0.287)
- **Smallest effect**: Overall Compliance (d = 0.028)
- **Average effect size**: |d| = 0.158 (small)

### **üîÑ Trust Calibration**
Both conditions showed similar trust calibration patterns:
- **High appropriate compliance**: ~88% (good trust in correct guidance)
- **High overcompliance**: ~76% (automation bias problem)
- **Low undercompliance**: ~11% (rare rejection of correct guidance)

---

## üéì **Theoretical Implications**

### **1. Proxemics in VR May Not Apply to Human-AI Interaction**
The null findings suggest that **Hall's proxemics theory may not extend to human-AI interaction** in virtual environments. Unlike human-human interaction, spatial distance may not influence trust formation with AI agents.

### **2. AI Agents May Be Perceived Differently**
Participants may not process AI agents through the same spatial-social frameworks as human agents. The lack of distance effects suggests:
- **AI agents may be processed as tools rather than social entities**
- **Spatial metaphors may not apply to human-AI trust**
- **Trust formation with AI may rely on different mechanisms**

### **3. VR-Specific Considerations**
Several VR-specific factors may explain the null findings:
- **Avatar presence**: Participants could see their own hands/limbs, providing spatial grounding
- **Task focus**: Navigation task may have dominated attention over spatial relationships
- **AI embodiment**: Virtual agent embodiment may not trigger spatial processing

---

## üîß **Design Implications**

### **1. Spatial Design Less Critical for AI Trust**
Findings suggest that **spatial positioning of AI agents may be less important** for trust formation than previously thought. Designers may focus on other factors:
- **Agent competence and performance**
- **Communication style and personality**
- **Task-relevant capabilities**

### **2. VR Environment Flexibility**
The lack of distance effects provides **design flexibility** for VR environments:
- **Agents can be positioned anywhere without trust consequences**
- **Focus can shift to other interaction design elements**
- **Spatial layout can prioritize task efficiency over trust optimization**

### **3. Trust Building Strategies**
Since spatial proximity doesn't affect trust, focus should shift to:
- **Demonstrating competence and reliability**
- **Providing transparent and helpful communication**
- **Ensuring appropriate trust calibration**

---

## üìä **Comparison with Task 1**

### **Contrasting Findings**
- **Task 1 (Memory Function)**: Large effects (d = 0.89-2.45) on decision time
- **Task 2 (Distance Proximity)**: No effects (d = 0.03-0.29) on any measures

### **Implications**
- **Memory function** appears to be a **strong trust determinant**
- **Spatial proximity** appears to be a **weak trust determinant**
- **Functional capabilities** may matter more than **spatial relationships**

---

## üö® **Limitations**

### **1. VR-Specific Limitations**
- **Spatial perception**: VR spatial perception may differ from real-world
- **Avatar embodiment**: Participant avatars may have influenced spatial processing
- **Task context**: Navigation task may have minimized spatial attention

### **2. Design Limitations**
- **Distance range**: 1.8m-5.4m range may not have been sufficient
- **Agent embodiment**: Virtual agent may not have triggered spatial processing
- **Interaction type**: Limited physical interaction may have reduced spatial relevance

### **3. Measurement Limitations**
- **Trust measures**: May not capture subtle spatial effects
- **Behavioral measures**: May not reflect spatial processing
- **Sample size**: May have been insufficient for small effects

---

## üîÆ **Future Research Directions**

### **1. Extended Distance Range**
- **Test wider distance ranges** (0.5m-10m)
- **Include intimate distances** (< 1m)
- **Test extreme distances** (> 10m)

### **2. Different Agent Embodiments**
- **Human-like avatars** vs abstract representations
- **Anthropomorphic vs non-anthropomorphic agents**
- **Static vs dynamic agent positioning**

### **3. Different Interaction Types**
- **Collaborative tasks** requiring spatial coordination
- **Social interaction tasks** emphasizing spatial relationships
- **Tasks requiring physical proximity** for success

### **4. Individual Differences**
- **Cultural differences** in spatial preferences
- **Personality factors** affecting spatial processing
- **VR experience levels** influencing spatial perception

---

## üéØ **Conclusion**

The Distance Proximity Analysis revealed **no significant effects of spatial distance on trust** in human-AI collaboration within VR environments. This finding challenges the direct application of Hall's proxemics theory to human-AI interaction and suggests that **spatial relationships may be less important for AI trust formation** than previously hypothesized.

**Key Takeaway**: While spatial proximity strongly influences human-human interaction, it appears to have minimal impact on human-AI trust in virtual environments. This provides important design flexibility for VR applications and suggests that **functional capabilities and communication style may be more critical for AI trust** than spatial positioning.

The null findings are valuable in themselves, providing evidence that **different mechanisms may govern trust formation with AI agents** compared to human agents, and that **proxemics theory may need modification** for human-AI interaction contexts.

---

**Status**: ‚úÖ **Analysis Complete**  
**Significant Findings**: 0 out of 11 measures  
**Largest Effect Size**: d = -0.287 (Trust Change)  
**Conclusion**: **No distance proximity effects on trust**


