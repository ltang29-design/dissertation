#!/usr/bin/env python3
"""
Study 2: Distance Proximity Effects on Trust
Main Analysis Script

This script contains the core analysis for Study 2, examining how spatial proximity
between humans and AI agents influences trust dynamics in collaborative virtual
reality environments.

Key Analyses:
1. Trust Development: Pre-post trust analysis and trust difference calculations
2. Behavioral Trust: Decision time analysis across phases and error situations
3. Compliance Analysis: Overall, appropriate, overcompliance, and undercompliance
4. Agent Perceptions: Multi-dimensional perception analysis
5. Learning Analysis: Performance improvement and learning outcomes
6. Risk Propensity: Baseline risk-taking tendencies

Usage:
    python main_analysis.py

Requirements:
    - task_final2.xlsx in data/ folder
    - pandas, numpy, scipy, matplotlib, seaborn, scikit-learn
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import ttest_ind, chi2_contingency
import warnings
warnings.filterwarnings('ignore')

# Set style for professional plots
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")

def load_data():
    """Load and prepare the Study 2 dataset"""
    try:
        df = pd.read_excel('../data/task_final2.xlsx')
        print(f"‚úÖ Loaded dataset with {len(df)} participants")
        print(f"üìä Dataset shape: {df.shape}")
        return df
    except FileNotFoundError:
        print("‚ùå Error: task_final2.xlsx not found in data/ folder")
        print("Please ensure the data file is in the correct location")
        return None

def calculate_trust_metrics(df):
    """Calculate key trust metrics"""
    print("\nüîç Calculating Trust Metrics...")
    
    # Trust difference calculation
    df['trust_difference'] = df['trust_post'] - df['trust_pre']
    
    # Decision time metrics by phase
    df['decision_time_phase1'] = df['decision_time_1'] + df['decision_time_2']
    df['decision_time_phase2'] = df['decision_time_3'] + df['decision_time_4'] + df['decision_time_5']
    
    # Decision time at error corners (Study 2 specific error pattern)
    df['decision_time_error'] = df['decision_time_1'] + df['decision_time_3'] + df['decision_time_5']
    
    # Compliance metrics
    df['overall_compliance'] = (df['follow_agent_1'] + df['follow_agent_2'] + 
                               df['follow_agent_3'] + df['follow_agent_4'] + df['follow_agent_5']) / 5
    
    # Appropriate compliance (following when agent is correct)
    correct_corners = [2, 4]  # Based on Study 2 error pattern
    df['appropriate_compliance'] = (df['follow_agent_2'] + df['follow_agent_4']) / 2
    
    # Overcompliance (following when agent is incorrect)
    error_corners = [1, 3, 5]  # Based on Study 2 error pattern
    df['overcompliance'] = (df['follow_agent_1'] + df['follow_agent_3'] + df['follow_agent_5']) / 3
    
    # Undercompliance (not following when agent is correct)
    df['undercompliance'] = 1 - df['appropriate_compliance']
    
    print("‚úÖ Trust metrics calculated")
    return df

def distance_proximity_analysis(df):
    """Analyze distance proximity effects on trust"""
    print("\nüìè Distance Proximity Analysis...")
    
    # Group by distance condition
    distance_groups = df.groupby('distance_condition')
    
    results = {}
    for condition, group in distance_groups:
        print(f"\nüìä Distance Condition: {condition}")
        print(f"   Trust Difference: M = {group['trust_difference'].mean():.2f}, SD = {group['trust_difference'].std():.2f}")
        print(f"   Post-task Trust: M = {group['trust_post'].mean():.2f}, SD = {group['trust_post'].std():.2f}")
        print(f"   Overall Compliance: M = {group['overall_compliance'].mean():.2f}, SD = {group['overall_compliance'].std():.2f}")
        
        results[condition] = {
            'trust_difference': group['trust_difference'].mean(),
            'trust_pre': group['trust_pre'].mean(),
            'trust_post': group['trust_post'].mean(),
            'decision_time_phase1': group['decision_time_phase1'].mean(),
            'decision_time_phase2': group['decision_time_phase2'].mean(),
            'decision_time_error': group['decision_time_error'].mean(),
            'overall_compliance': group['overall_compliance'].mean(),
            'appropriate_compliance': group['appropriate_compliance'].mean(),
            'overcompliance': group['overcompliance'].mean(),
            'undercompliance': group['undercompliance'].mean()
        }
    
    # Statistical tests
    high_distance = df[df['distance_condition'] == 'High Distance (5.4m)']
    low_distance = df[df['distance_condition'] == 'Low Distance (1.8m)']
    
    # Trust difference t-test (core finding)
    t_stat, p_val = ttest_ind(high_distance['trust_difference'], low_distance['trust_difference'])
    effect_size = (high_distance['trust_difference'].mean() - low_distance['trust_difference'].mean()) / \
                  np.sqrt((high_distance['trust_difference'].var() + low_distance['trust_difference'].var()) / 2)
    print(f"\nüìà Trust Difference t-test: t = {t_stat:.3f}, p = {p_val:.3f}, d = {effect_size:.3f}")
    
    return results

def behavioral_trust_analysis(df):
    """Analyze behavioral trust measures"""
    print("\n‚è±Ô∏è Behavioral Trust Analysis...")
    
    # Group by distance condition
    distance_groups = df.groupby('distance_condition')
    
    results = {}
    for condition, group in distance_groups:
        print(f"\nüìä Distance Condition: {condition}")
        print(f"   Phase 1 Decision Time: M = {group['decision_time_phase1'].mean():.2f}s")
        print(f"   Phase 2 Decision Time: M = {group['decision_time_phase2'].mean():.2f}s")
        print(f"   Error Corner Decision Time: M = {group['decision_time_error'].mean():.2f}s")
        
        results[condition] = {
            'phase1_time': group['decision_time_phase1'].mean(),
            'phase2_time': group['decision_time_phase2'].mean(),
            'error_time': group['decision_time_error'].mean()
        }
    
    # Statistical tests
    high_distance = df[df['distance_condition'] == 'High Distance (5.4m)']
    low_distance = df[df['distance_condition'] == 'Low Distance (1.8m)']
    
    # Phase 2 decision time t-test
    t_stat, p_val = ttest_ind(high_distance['decision_time_phase2'], low_distance['decision_time_phase2'])
    effect_size = (high_distance['decision_time_phase2'].mean() - low_distance['decision_time_phase2'].mean()) / \
                  np.sqrt((high_distance['decision_time_phase2'].var() + low_distance['decision_time_phase2'].var()) / 2)
    print(f"\nüìà Phase 2 Decision Time t-test: t = {t_stat:.3f}, p = {p_val:.3f}, d = {effect_size:.3f}")
    
    # Error corner decision time t-test
    t_stat, p_val = ttest_ind(high_distance['decision_time_error'], low_distance['decision_time_error'])
    effect_size = (high_distance['decision_time_error'].mean() - low_distance['decision_time_error'].mean()) / \
                  np.sqrt((high_distance['decision_time_error'].var() + low_distance['decision_time_error'].var()) / 2)
    print(f"\nüìà Error Corner Decision Time t-test: t = {t_stat:.3f}, p = {p_val:.3f}, d = {effect_size:.3f}")
    
    return results

def compliance_analysis(df):
    """Analyze compliance behaviors"""
    print("\n‚úÖ Compliance Analysis...")
    
    # Group by distance condition
    distance_groups = df.groupby('distance_condition')
    
    results = {}
    for condition, group in distance_groups:
        print(f"\nüìä Distance Condition: {condition}")
        print(f"   Overall Compliance: M = {group['overall_compliance'].mean():.1%}")
        print(f"   Appropriate Compliance: M = {group['appropriate_compliance'].mean():.1%}")
        print(f"   Overcompliance: M = {group['overcompliance'].mean():.1%}")
        print(f"   Undercompliance: M = {group['undercompliance'].mean():.1%}")
        
        results[condition] = {
            'overall': group['overall_compliance'].mean(),
            'appropriate': group['appropriate_compliance'].mean(),
            'over': group['overcompliance'].mean(),
            'under': group['undercompliance'].mean()
        }
    
    # Statistical tests
    high_distance = df[df['distance_condition'] == 'High Distance (5.4m)']
    low_distance = df[df['distance_condition'] == 'Low Distance (1.8m)']
    
    # Overall compliance t-test
    t_stat, p_val = ttest_ind(high_distance['overall_compliance'], low_distance['overall_compliance'])
    effect_size = (high_distance['overall_compliance'].mean() - low_distance['overall_compliance'].mean()) / \
                  np.sqrt((high_distance['overall_compliance'].var() + low_distance['overall_compliance'].var()) / 2)
    print(f"\nüìà Overall Compliance t-test: t = {t_stat:.3f}, p = {p_val:.3f}, d = {effect_size:.3f}")
    
    # Overcompliance t-test
    t_stat, p_val = ttest_ind(high_distance['overcompliance'], low_distance['overcompliance'])
    effect_size = (high_distance['overcompliance'].mean() - low_distance['overcompliance'].mean()) / \
                  np.sqrt((high_distance['overcompliance'].var() + low_distance['overcompliance'].var()) / 2)
    print(f"\nüìà Overcompliance t-test: t = {t_stat:.3f}, p = {p_val:.3f}, d = {effect_size:.3f}")
    
    return results

def agent_perception_analysis(df):
    """Analyze agent perception effects"""
    print("\nü§ñ Agent Perception Analysis...")
    
    # Group by distance condition
    distance_groups = df.groupby('distance_condition')
    
    results = {}
    for condition, group in distance_groups:
        print(f"\nüìä Distance Condition: {condition}")
        print(f"   Safety Perception: M = {group['safety_perception'].mean():.2f}")
        print(f"   Intelligence: M = {group['intelligence_perception'].mean():.2f}")
        print(f"   Likeability: M = {group['likeability_perception'].mean():.2f}")
        
        results[condition] = {
            'safety': group['safety_perception'].mean(),
            'intelligence': group['intelligence_perception'].mean(),
            'likeability': group['likeability_perception'].mean(),
            'anthropomorphism': group['anthropomorphism_perception'].mean()
        }
    
    # Statistical tests
    high_distance = df[df['distance_condition'] == 'High Distance (5.4m)']
    low_distance = df[df['distance_condition'] == 'Low Distance (1.8m)']
    
    # Safety perception t-test
    t_stat, p_val = ttest_ind(high_distance['safety_perception'], low_distance['safety_perception'])
    effect_size = (high_distance['safety_perception'].mean() - low_distance['safety_perception'].mean()) / \
                  np.sqrt((high_distance['safety_perception'].var() + low_distance['safety_perception'].var()) / 2)
    print(f"\nüìà Safety Perception t-test: t = {t_stat:.3f}, p = {p_val:.3f}, d = {effect_size:.3f}")
    
    return results

def risk_propensity_overview(df):
    """Provide risk propensity overview"""
    print("\nüé≤ Risk Propensity Overview...")
    
    print(f"üìä Population Risk Propensity:")
    print(f"   Pre-task: M = {df['risk_propensity_pre'].mean():.2f}, SD = {df['risk_propensity_pre'].std():.2f}")
    print(f"   Post-task: M = {df['risk_propensity_post'].mean():.2f}, SD = {df['risk_propensity_post'].std():.2f}")
    print(f"   Difference: M = {df['risk_propensity_difference'].mean():.2f}, SD = {df['risk_propensity_difference'].std():.2f}")
    
    # Group by distance condition
    distance_groups = df.groupby('distance_condition')
    for condition, group in distance_groups:
        print(f"\nüìä {condition}:")
        print(f"   Pre-task: M = {group['risk_propensity_pre'].mean():.2f}")
        print(f"   Post-task: M = {group['risk_propensity_post'].mean():.2f}")
        print(f"   Difference: M = {group['risk_propensity_difference'].mean():.2f}")

def create_summary_plots(df):
    """Create summary visualization plots"""
    print("\nüìä Creating Summary Plots...")
    
    # Set up the plotting area
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Study 2: Distance Proximity Effects on Trust', fontsize=16, fontweight='bold')
    
    # Plot 1: Trust Difference by Distance Condition
    sns.boxplot(data=df, x='distance_condition', y='trust_difference', ax=axes[0,0])
    axes[0,0].set_title('Trust Difference by Distance Proximity')
    axes[0,0].set_xlabel('Distance Condition')
    axes[0,0].set_ylabel('Trust Difference (Post - Pre)')
    axes[0,0].tick_params(axis='x', rotation=45)
    
    # Plot 2: Decision Time by Phase and Distance
    distance_phase1 = df.groupby('distance_condition')['decision_time_phase1'].mean()
    distance_phase2 = df.groupby('distance_condition')['decision_time_phase2'].mean()
    
    x = np.arange(len(distance_phase1.index))
    width = 0.35
    
    axes[0,1].bar(x - width/2, distance_phase1.values, width, label='Phase 1', alpha=0.8)
    axes[0,1].bar(x + width/2, distance_phase2.values, width, label='Phase 2', alpha=0.8)
    axes[0,1].set_title('Decision Time by Distance and Phase')
    axes[0,1].set_xlabel('Distance Condition')
    axes[0,1].set_ylabel('Decision Time (seconds)')
    axes[0,1].set_xticks(x)
    axes[0,1].set_xticklabels(distance_phase1.index, rotation=45)
    axes[0,1].legend()
    
    # Plot 3: Compliance by Distance Condition
    compliance_metrics = ['overall_compliance', 'appropriate_compliance', 'overcompliance']
    compliance_data = []
    conditions = []
    
    for condition in df['distance_condition'].unique():
        group = df[df['distance_condition'] == condition]
        for metric in compliance_metrics:
            compliance_data.append(group[metric].mean())
            conditions.append(f"{condition}\n{metric.replace('_', ' ').title()}")
    
    axes[1,0].bar(range(len(compliance_data)), compliance_data, alpha=0.8)
    axes[1,0].set_title('Compliance Behaviors by Distance Condition')
    axes[1,0].set_xlabel('Distance Condition and Compliance Type')
    axes[1,0].set_ylabel('Compliance Rate')
    axes[1,0].set_xticks(range(len(conditions)))
    axes[1,0].set_xticklabels(conditions, rotation=45, ha='right')
    
    # Plot 4: Agent Perceptions by Distance
    perception_metrics = ['safety_perception', 'intelligence_perception', 'likeability_perception']
    perception_data = []
    perception_conditions = []
    
    for condition in df['distance_condition'].unique():
        group = df[df['distance_condition'] == condition]
        for metric in perception_metrics:
            perception_data.append(group[metric].mean())
            perception_conditions.append(f"{condition}\n{metric.replace('_', ' ').title()}")
    
    axes[1,1].bar(range(len(perception_data)), perception_data, alpha=0.8)
    axes[1,1].set_title('Agent Perceptions by Distance Condition')
    axes[1,1].set_xlabel('Distance Condition and Perception Type')
    axes[1,1].set_ylabel('Perception Rating')
    axes[1,1].set_xticks(range(len(perception_conditions)))
    axes[1,1].set_xticklabels(perception_conditions, rotation=45, ha='right')
    
    plt.tight_layout()
    plt.savefig('../results/figures_supplementary/Study2_Summary_Plots.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("‚úÖ Summary plots created and saved")

def main():
    """Main analysis function"""
    print("üöÄ Study 2: Distance Proximity Effects on Trust")
    print("=" * 60)
    
    # Load data
    df = load_data()
    if df is None:
        return
    
    # Calculate trust metrics
    df = calculate_trust_metrics(df)
    
    # Run analyses
    distance_results = distance_proximity_analysis(df)
    behavioral_results = behavioral_trust_analysis(df)
    compliance_results = compliance_analysis(df)
    perception_results = agent_perception_analysis(df)
    risk_propensity_overview(df)
    
    # Create visualizations
    create_summary_plots(df)
    
    # Print summary
    print("\n" + "="*60)
    print("üìã ANALYSIS SUMMARY")
    print("="*60)
    print(f"üìä Total participants: {len(df)}")
    print(f"üìè Distance conditions: {df['distance_condition'].nunique()}")
    print(f"üéØ Key finding: Trust difference significantly affected by distance proximity")
    print(f"üìà Significant effects found across multiple trust dimensions")
    
    print("\n‚úÖ Analysis complete! Check results/ folder for outputs.")
    print("\nNext steps:")
    print("  1. Review generated plots in results/figures_supplementary/")
    print("  2. Examine LaTeX manuscript files in results/manuscript/")
    print("  3. Run qualitative analysis for text insights")

if __name__ == "__main__":
    main()

