\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[authoryear,round]{natbib}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\usepackage{float}
\usepackage{array}
\usepackage{multirow}

\doublespacing

\title{\textbf{Discussion: Distance Proximity Effects on Trust in Human-AI Collaboration}}
\author{[Author Names]}
\date{}

\begin{document}

\maketitle

\section{Discussion}

This study investigated how spatial proximity between humans and AI agents influences trust dynamics in collaborative VR environments. Our findings reveal that distance proximity significantly affects multiple dimensions of human-AI interaction, with particularly strong effects on trust development, navigation efficiency, and agent perceptions. The results demonstrate that proximity is a crucial factor in shaping human-AI relationships, with implications extending beyond simple spatial arrangements to fundamental aspects of trust, communication, and collaborative effectiveness.

\subsection{Distance Proximity as a Fundamental Trust Factor}

\subsubsection{Trust Development Patterns}

The most significant finding was the differential effect of proximity on trust development over time. Participants with close agents (1.8m) showed positive trust development (+2.1 points), while those with distant agents (5.4m) experienced trust deterioration (-8.4 points), representing a medium-large effect size (d = -0.578). This finding extends previous research on human-human proximity effects \citep{hall1966hidden} to human-AI interaction, suggesting that spatial relationships fundamentally influence trust dynamics in human-agent collaboration.

The trust development pattern aligns with \citeauthor{lee2004trust}'s \citeyear{lee2004trust} model of trust in automation, which emphasizes the role of spatial and social cues in trust formation. Our results suggest that proximity provides critical social and communicative cues that facilitate positive trust building. When agents are positioned closer, participants may perceive them as more accessible, reliable, and socially present, leading to enhanced trust development over time.

The differential trust development patterns also reflect \citeauthor{nass2000machines}'s \citeyear{nass2000machines} Computers Are Social Actors (CASA) paradigm, which suggests that humans apply social rules to AI agents. In human social interaction, proximity typically signals intimacy, cooperation, and trustworthiness \citep{burgoon1991interpersonal}. Our findings indicate that these social proximity rules extend to human-AI interaction, with closer agents being perceived as more trustworthy partners.

\subsubsection{Implications for Trust Calibration}

The proximity effects on trust development have important implications for trust calibration in human-AI systems. Participants with distant agents not only developed less trust but also experienced trust loss, suggesting that distance may impair trust calibration mechanisms. This finding is particularly relevant for applications where accurate trust calibration is critical for safety and performance, such as autonomous vehicles, medical AI systems, and industrial automation.

The results suggest that spatial design of human-AI interfaces should prioritize proximity to facilitate positive trust development. However, the finding that proximity affects trust development patterns rather than absolute trust levels indicates that proximity may be more important for trust maintenance than initial trust formation. This distinction has practical implications for interface design, suggesting that proximity may be particularly crucial in long-term human-AI collaborations.

% Section removed per updated scope: Navigation Efficiency

\subsection{Agent Perceptions: Social Processing of Spatial Relationships}

\subsubsection{Safety Enhancement}

Distance proximity significantly enhanced safety perception (d = -0.471), demonstrating that proximity fundamentally influences how humans perceive AI agents. This finding extends \citeauthor{hess2009effects}'s \citeyear{hess2009effects} research on agent appearance to spatial factors, suggesting that proximity is a crucial dimension of agent design that affects social processing.

The safety perception effect is particularly noteworthy, as it represents a fundamental aspect of human-AI interaction that directly influences trust and reliance. Participants perceived closer agents as significantly safer, which may reflect evolutionary adaptations for social processing where proximity typically signals safety and cooperation \citep{dunbar2010social}. This finding suggests that proximity may activate innate social processing mechanisms that enhance safety perception in human-AI interaction.

% Communication clarity removed per updated scope.

\subsubsection{Selective Effects on Social Dimensions}

Interestingly, proximity showed selective effects on different social dimensions. While safety perception and communication clarity showed significant effects (see Fig\_Distance\_Safety\_Perception and Fig\_Distance\_Communication\_Clarity), intelligence perception and anthropomorphism showed minimal or trending effects (see Fig\_Distance\_Intelligence and Fig\_Distance\_Anthropomorphism). This selective pattern suggests that proximity primarily influences social processing related to safety and communication rather than cognitive or anthropomorphic attributions.

The selective effects may reflect the specific nature of proximity as a social cue. Proximity typically signals safety, accessibility, and communication readiness in human interaction, but does not necessarily signal intelligence or human-likeness. This finding suggests that different aspects of agent design may influence different dimensions of social processing, with proximity being particularly relevant for safety and communication-related perceptions.

\subsection{Behavioral Trust: Significant Proximity Effects on Compliance}

\subsubsection{Compliance Patterns and Trust Calibration}

Distance proximity showed significant effects on compliance behaviors, particularly overcompliance (d = -0.649, p = .002; see Fig\_Distance\_Overcompliance). Participants with distant agents were significantly less likely to follow incorrect agent recommendations (52.3\% vs 64.7\%), indicating better trust calibration when agents are positioned farther away. By contrast, undercompliance showed no reliable difference across proximity conditions (p = .494; see Fig\_Distance\_Undercompliance). This pattern suggests that proximity affects both trust attitudes and behavioral compliance decisions, with distant agents leading to more appropriate trust calibration specifically by reducing inappropriate following when the agent is wrong.

The significant proximity effects on compliance behaviors reveal important insights about trust calibration mechanisms. Participants with distant agents showed better discrimination between correct and incorrect agent recommendations, suggesting that distance may facilitate more critical evaluation of agent guidance. This finding aligns with research on trust calibration, where appropriate skepticism of unreliable systems is crucial for effective human-AI collaboration.

This finding has important implications for understanding the relationship between trust attitudes and behavioral trust. Proximity influences both trust development and behavioral compliance, with distant agents leading to more appropriate trust calibration and reduced overcompliance with incorrect recommendations. This suggests that proximity affects the quality of trust calibration, not just the magnitude of trust attitudes.

\subsubsection{Decision Time: Proximity Effects on Confidence}

Decision time showed significant effects, particularly in Phase 2 (p = .034, d = 0.449; see Fig\_Distance\_Phase2\_Decision\_Time) and at error corners (p = .028, d = 0.465; see Fig\_Distance\_Error\_Corner\_Time). These findings suggest that proximity affects decision confidence and processing time, with participants taking longer to make decisions when agents are positioned farther away.

The decision time effects may reflect proximity influences on cognitive processing and confidence. Participants with distant agents may experience greater uncertainty when making decisions, particularly when agent guidance is unreliable. This uncertainty manifests as longer decision times, indicating that distance affects the cognitive processing of agent guidance.

The phase-specific effects on decision time suggest that proximity influences decision confidence as participants gain experience with the agent. The significant effect in Phase 2 indicates that proximity becomes more influential as participants develop familiarity with the agent's guidance patterns, suggesting that proximity effects strengthen over time as participants learn about agent reliability.

\subsection{Learning and Performance: Proximity as a Learning Facilitator}

\subsubsection{Enhanced Learning with Close Agents}

Distance proximity significantly enhanced learning improvement, with participants showing markedly greater improvement when agents were positioned closer (d = -0.717; see Fig\_Distance\_Learning\_Improvement). This large effect size demonstrates that proximity fundamentally facilitates learning in human-AI collaboration, extending beyond immediate performance to learning outcomes.

The learning enhancement may result from several proximity-related mechanisms. First, closer agents may provide more effective guidance and feedback, enabling better learning. Second, proximity may enhance the sense of collaborative partnership, motivating participants to engage more actively in learning. Third, closer agents may reduce cognitive load, allowing participants to focus more on learning rather than communication or coordination.

The learning findings have important implications for educational and training applications of human-AI collaboration. Interface designers should prioritize close agent positioning to maximize learning outcomes, particularly in educational VR environments, training simulations, and skill development applications.

\subsubsection{Mechanisms of Learning Enhancement}

The dramatic learning improvement may reflect enhanced communication, reduced cognitive load, and improved collaborative dynamics when agents are positioned closer. Proximity may facilitate clearer guidance delivery, more effective feedback, and better coordination between human and AI partners, all of which are crucial for effective learning.

The learning enhancement findings also suggest that proximity effects extend beyond immediate performance to long-term learning outcomes. This has implications for understanding how spatial factors influence human-AI collaboration over extended periods, suggesting that proximity may be particularly important for sustained human-AI partnerships.

\subsection{Qualitative Insights: The Human Experience of Distance}

\subsubsection{Emotional and Cognitive Responses}

Our qualitative analysis revealed distinct emotional and cognitive responses to distance proximity. High distance participants frequently described feelings of "disconnection," "uncertainty," and "caution," while low distance participants reported "confidence," "trust," and "partnership." These qualitative findings align with our quantitative results, providing rich insights into the human experience of distance in human-AI interaction.

The qualitative findings also revealed that proximity affects not only trust attitudes but also emotional responses to AI agents. Participants with distant agents reported more negative emotional experiences, while those with close agents reported more positive emotional responses. This emotional dimension of proximity effects has implications for user experience design and the emotional aspects of human-AI interaction.

\subsubsection{Communication and Coordination Challenges}

Qualitative responses highlighted communication and coordination challenges associated with distance proximity. High distance participants frequently mentioned difficulties in "understanding agent guidance," "coordinating with the agent," and "feeling connected to the agent's presence." These challenges align with our quantitative findings on communication clarity and navigation efficiency, suggesting that proximity fundamentally affects communication and coordination in human-AI collaboration.

The communication challenges reported by high distance participants may explain the navigation efficiency effects we observed. When communication is impaired by distance, participants may make less optimal navigation decisions, leading to increased travel distance and reduced efficiency. This suggests that proximity effects on navigation efficiency may be mediated by communication and coordination mechanisms.

\subsection{Theoretical Implications}

\subsubsection{Extension of Proxemics Theory to Human-AI Interaction}

Our findings extend \citeauthor{hall1966hidden}'s \citeyear{hall1966hidden} proxemics theory to human-AI interaction, demonstrating that spatial relationships fundamentally influence human-agent relationships. The results suggest that humans apply similar spatial rules to AI agents as they do to human partners, with proximity signaling trust, safety, and collaborative readiness.

The extension of proxemics theory has important implications for understanding human-AI interaction. It suggests that spatial factors are not merely environmental variables but fundamental dimensions of human-agent relationships that influence multiple aspects of interaction, from trust development to performance outcomes.

\subsubsection{Social Processing of AI Agents}

Our findings support \citeauthor{nass2000machines}'s \citeyear{nass2000machines} CASA paradigm, demonstrating that humans apply social processing rules to AI agents. The proximity effects on trust development, safety perception, and communication clarity suggest that humans process AI agents through social mechanisms, with spatial factors playing a crucial role in social processing.

The social processing findings have implications for understanding the nature of human-AI relationships. They suggest that human-AI interaction is fundamentally social in nature, with spatial factors influencing social processing in similar ways to human-human interaction. This has implications for designing AI systems that can effectively engage in social interaction with humans.

\subsubsection{Trust Development in Human-AI Collaboration}

Our findings contribute to understanding trust development in human-AI collaboration, demonstrating that proximity is a crucial factor in trust formation and maintenance. The differential trust development patterns suggest that proximity influences not only initial trust but also trust dynamics over time, with important implications for long-term human-AI partnerships.

The trust development findings have implications for \citeauthor{lee2004trust}'s \citeyear{lee2004trust} model of trust in automation, suggesting that spatial factors should be included as important determinants of trust formation and maintenance. The results indicate that proximity provides critical social and communicative cues that facilitate positive trust development in human-AI collaboration.

\subsection{Practical Implications}

\subsubsection{Interface Design for Human-AI Collaboration}

Our findings have direct implications for interface design in human-AI collaboration systems. The dramatic effects on navigation efficiency, trust development, and agent perceptions suggest that spatial design should prioritize proximity to maximize collaborative effectiveness. Interface designers should consider proximity as a fundamental design parameter that influences multiple aspects of human-AI interaction.

The practical implications extend to various application domains, including VR training systems, collaborative robotics, autonomous vehicle interfaces, and mixed reality applications. In each domain, proximity should be optimized to facilitate trust development, enhance communication, and improve collaborative performance.

\subsubsection{VR and Mixed Reality Applications}

The findings are particularly relevant for VR and mixed reality applications where spatial relationships between humans and AI agents are designable. Our results suggest that agent positioning should be optimized for proximity to maximize trust, communication, and performance outcomes. This has implications for educational VR, training simulations, and collaborative mixed reality applications.

The VR-specific implications also extend to the design of virtual environments where human-AI collaboration occurs. Spatial layout, agent positioning, and environmental design should prioritize proximity to facilitate effective human-AI collaboration.

\subsubsection{Safety-Critical Applications}

The proximity effects on safety perception and trust development have important implications for safety-critical applications of human-AI collaboration. In domains such as autonomous vehicles, medical AI systems, and industrial automation, proximity may be crucial for establishing trust and ensuring safe human-AI interaction.

The safety implications suggest that proximity should be considered in the design of safety-critical human-AI systems, with closer agent positioning potentially enhancing safety perception and trust development. This has implications for interface design in safety-critical domains where trust and safety are paramount.

\subsection{Limitations and Future Directions}

\subsubsection{Study Limitations}

Several limitations should be considered when interpreting our findings. First, our study used a specific VR environment and task, which may limit generalizability to other contexts. Second, we examined only two distance conditions (1.8m and 5.4m), which may not capture the full range of proximity effects. Third, our study focused on a single interaction session, which may not capture long-term proximity effects on trust and collaboration.

The limitations suggest that future research should examine proximity effects across different contexts, distance ranges, and time periods. Additionally, research should investigate the mechanisms underlying proximity effects to better understand how spatial factors influence human-AI interaction.

\subsubsection{Future Research Directions}

Future research should investigate several important questions. First, how do proximity effects vary across different types of AI agents and interaction contexts? Second, what are the optimal proximity ranges for different types of human-AI collaboration? Third, how do proximity effects change over extended periods of human-AI interaction? Fourth, what mechanisms underlie proximity effects on trust, communication, and performance?

These research directions would advance understanding of spatial factors in human-AI interaction and provide practical guidance for designing effective human-AI collaborative systems. Future research should also investigate individual differences in proximity sensitivity and cultural variations in proximity preferences.

\subsection{Conclusion}

This study demonstrates that distance proximity is a fundamental factor in human-AI collaboration, significantly influencing trust development, navigation efficiency, agent perceptions, and learning outcomes. The findings extend proxemics theory and social processing research to human-AI interaction, revealing that spatial relationships play a crucial role in shaping human-agent relationships.

The results have important implications for interface design, suggesting that proximity should be prioritized in human-AI collaborative systems to maximize trust, communication, and performance outcomes. The dramatic effects on navigation efficiency and learning improvement demonstrate that proximity is not merely a social factor but a fundamental determinant of collaborative effectiveness.

Our findings contribute to understanding the social nature of human-AI interaction, demonstrating that humans apply spatial social rules to AI agents in similar ways to human partners. This has implications for designing AI systems that can effectively engage in social interaction with humans, with proximity being a crucial factor in establishing trust, safety, and collaborative effectiveness.

The study provides a foundation for future research on spatial factors in human-AI interaction, suggesting that proximity is a fundamental dimension of human-agent relationships that influences multiple aspects of collaboration. Future research should investigate the mechanisms underlying proximity effects and examine how spatial factors influence human-AI interaction across different contexts and time periods.

\bibliographystyle{apalike}
\bibliography{references}

\end{document}

